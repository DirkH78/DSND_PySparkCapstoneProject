# Udacity Nanodegree big data Capstone Project - Spark Project: Sparkify
This project was created for Udacity students who subscribed for the "Data Science Nanodegree" and serves as a Capstone project to summerize and deepen some of the techniques that were introduced within this course.
This repository reflects my submission for this project.
## Content
* Sparkify.ipynb: jupyter Notebook with projec code
* README.md: this documentation
* Analysis.md: detailed documentation about findings
## What did I learn?
I learned how to manipulate large and realistic datasets with Spark to engineer relevant features for predicting churn. I learned how to use Spark MLlib to build machine learning models with large datasets, far beyond what could be done with non-distributed technologies like scikit-learn.
### Summary
* Load large datasets into Spark and manipulate them using Spark SQL and Spark Dataframes
* Use the machine learning APIs within Spark ML to build and tune models
* Integrate the skills you've learned in the Spark course and the Data Scientist Nanodegree program
## Project Instructions
> "The full dataset is 12GB, of which you can analyze a mini subset in the workspace on the following page. Optionally, you can choose to follow the instructions in the Extracurricular course to deploy a Spark cluster on the cloud using AWS or IBM Cloud to analyze a larger amount of data. Currently we have the full 12GB dataset available to you if you use AWS. If you use IBM, you can download a medium sized dataset to upload to your cluster. Details on how to do this using AWS or IBM Cloud are included in the last lesson of the Extracurricular Spark Course content linked above. Note that this part is optional, and you will not receive credits to fund your deployment. You can do the IBM portion for free. Using AWS will cost you around $30 if you run a cluster up for a week with the settings we provide. Once you've built your model, either in the classroom workspace or in the cloud with AWS or IBM, download your notebook and complete the remaining components of your Data Scientist Capstone project, including thorough documentation in a README file in your Github repository, as well as a web app or blog post explaining the technical details of your project. Be sure to review the Project Rubric thoroughly before submitting your project."
## Requirements
Please keep in mind that the following requirements need to be met before this project can be run on your local machine.
### Software Requirements
> "This project must be written in Python 3.x. Given the free-form nature of the data scientist capstone, the software and libraries you will need to successfully complete your work will vary depending on the chosen application area and problem definition. Because of this, it is imperative that all necessary software and libraries used in your capstone project are accessible to the reviewer and clearly documented. Information regarding the software and libraries that your project makes use of should be included in your README document in your GitHub repo, along with your submission. Please note that proprietary software, software that requires private licenses, or software behind a paywall or login account should be avoided."
### Required Python Packages
* pyspark
* numpy
* pandas
* pyspark
* datetime
### Project requirements
The projects rubric can be found [here](https://review.udacity.com/#!/rubrics/2345/view).
### Required data sets
The data set used within this project was to big to be uploaded. If you would like to use the data set that was used for this project, please contact me. I could provide the data after Udacitys gave me permission to share the data.
## Documentation and Data Analysis
For a more detailed analysis and documentation visit the [analysis document](https://github.com/DirkH78/DSND_PySparkCapstoneProject/blob/master/Analysis.md)
## Acknowledgement
The project framework, project data and some of the images were kindly provided by the Udacity Data Scientist Nano-degree project team.